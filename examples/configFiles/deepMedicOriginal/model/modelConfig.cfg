#Default values are set internally, if the corresponding parameter is not found in the configuration file.

#[Optional but highly suggested] The name will be used in the filenames when saving the model.
#Default: "cnnModel"
modelName = "deepMedicOriginal"

#[Required] The main folder that the output will be placed.
folderForOutput = "../../../output/"


#================ MODEL PARAMETERS =================

#[Required] The number of classes in the task. Including background!
numberOfOutputClasses = 5
#[Required] The number of input channels, eg number of MRI modalities.
numberOfInputChannels = 2

#+++++++++++Normal pathway+++++++++++
#[Required] This list should have as many entries as the number of layers I want the normal-pathway to have.
#Each entry is an integer that specifies the number of Feature Maps to use in each of the layers.
numberFMsPerLayerNormal = [30, 30, 40, 40, 40, 40, 50, 50]
#[Required] This list should have as many entries as the number of layers in the normal pathway.
#Each entry should be a sublist with 3 entries. These should specify the dimensions of the kernel at the corresponding layer.
kernelDimPerLayerNormal = [[3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3]]

#[Optional] List with number of layers, at the output of which to make a residual connection with the input of the previous layer. Ala Kaiming He et al, Deep Residual Learning for Image Recognition.
#Note: Numbering starts from 1 for the first layer, which is not an acceptable value (no previous layer).
#Example: [4,6,8] will connect (add) to the output of Layer 4 the input of Layer 3. Also, input to 5th will be added to output of 6th, and input of 7th to output of 8th.
#Default: [], no residual connections
layersWithResidualConnNormal = []

#[Optional] Layers to make of lower rank. Ala Yani Ioannou et al, Training CNNs with Low-Rank Filters For Efficient Image Classification.
#Example: [3,5] will make the 3rd and 5th layers of lower rank.
#Default: []
lowerRankLayersNormal = []

#+++++++++++Subsampled pathway+++++++++++
#[Optional] Specify whether to use a subsampled pathway. If False, all subsampled-related parameters will be read but disregarded in the model-construction.
#Default: False
useSubsampledPathway = True

#[Optionals] The below parameters specify the subsampled-pathway architecture in a similar way as the normal.
#If they are ommitted and useSubsampledPathway is set to True, the subsampled pathway will be made similar to the normal pathway (suggested for easy use).
#[WARN] Subsampled pathway MUST have the same size of receptive field as the normal. Limitation in the code. User could easily specify different number of FMs. But care must be given if number of layers is changed. In this case, kernel sizes should also be adjusted to achieve same size of Rec.Field.
numberFMsPerLayerSubsampled = [30, 30, 40, 40, 40, 40, 50, 50]
kernelDimPerLayerSubsampled = [[3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3], [3,3,3]]

#[Optional] How much to downsample the image that the subsampled-pathway processes.
#Default: [3,3,3]
subsampleFactor = [3,3,3]

#[Optional] Residual Connections for subsampled pathway. See corresponding parameter for normal pathway.
#Default: mirrors the normal pathway, no residual connections
#layersWithResidualConnSubsampled = []

#[Optional] Layers to make of lower rank. See corresponding parameter for normal pathway.
#Default: Mirrors the normal pathway
#lowerRankLayersSubsampled = []

#+++++++++++FC Layers+++++++++++
#[Optional] After the last layers of the normal and subsampled pathways are concatenated, additional Fully Connected hidden layers can be added before the final classification layer.
#Specify a list, with as many entries as the number of ADDITIONAL FC layers (other than the classification layer) to add. The entries specify the number of Feature Maps to use.
#Default: []
numberFMsPerLayerFC = [150, 150]

#[Optional] Specify dimensions of the kernel in the first FC layer. This kernel combines the features from multiple scales. Applies to the final Classification layer if no hidden FC layers in network.
#Note: convolution with this kernel retains the size of the FMs (input is padded).
#Default: [1,1,1]
kernelDimFor1stFcLayer = [1,1,1]

#[Optional] Residual Connections for the FC hidden layers. See corresponding parameter for normal pathway.
#Default: [], no connections.
#layersWithResidualConnFC = []

#+++++++++++Size of Image Segments+++++++++++
#DeepMedic does not process patches of the image, but larger image-segments. Specify their size here.

#[Required] Size of training segments influence the captured distribution of samples from the different classes (see DeepMedic paper)
segmentsDimTrain = [25,25,25]
#[Optional] The size of segments to use during the validation-on-samples process that is performed throughout training if requested.
#Default: equal to receptive field, to validate on patches.
segmentsDimVal = [17,17,17]
#[Optional] Bigger image segments for Inference are safe to use and only speed up the process. Only limitation is the GPU memory.
#Default: equal to the training segment.
segmentsDimInference = [45,45,45]

#+++++++++++Batch Sizes+++++++++++
#[Required] The number of segments to create a batch.
#The samples in a training-batch are all processed and one optimization step is performed.
#Larger batches approximate the total data better and should positively impact optimization but are computationally more expensive (time and memory).
batchSizeTrain = 10
#[Optionals] Batch sizes for validation and inference only influence the speed. The bigger the better. Depends on the segment size and the model size how big batches can be fit in memory.
#Default: Equal to train-batch size.
batchSizeVal = 48
batchSizeInfer = 10

#[Optionals] Dropout Rates on the input connections of the various layers. Each list should have as many entries as the number of layers in the corresponding pathway.
# 0 = no dropout. 1= 100% drop of the neurons. Empty list for no dropout.
#Default: []
dropoutRatesNormal = []
dropoutRatesSubsampled = []
#Default: 50% dropout on every Fully Connected layer except for the first one after the concatenation
#Note: The list for FC rates should have one additional entry in comparison to "numberFMsPerLayerFC", for the classification layer.
dropoutRatesFc = [0.0, 0.5, 0.5] # +1 for the classification layer!

#[Optionals] Regularization L1 and L2.
#Defaults: L1_reg = 0.000001, L2_reg = 0.0001
L1_reg = 0.000001
L2_reg = 0.0001

#[Optional] Initialization method of the kernel weights. Specify 0 for classic, from the normal distribution N(0, 0.01). Otherwise specify 1 for the method of He et al from "Delving Deep into Rectifiers".
#Default: 1
initializeClassic0orDelving1 = 1
#[Optional] Activation Function for all convolutional layers. Specify 0 for ReLU, 1 for PreLU.
#Default: 1
relu0orPrelu1 = 1


#[Optional] Batch Normalization uses a rolling average of the mus and std for inference. Specify over how many batches (optimization steps) this rolling average should be taken. 
#Default : 60 (in our usual settings, with batchsize=10, segments per training subepoch=1000, and subepochs per epoch=20, this averages over 5 epochs).
rollAverageForBNOverThatManyBatches = 60

#+++++++++++Optimization+++++++++++
#[Optionals]
#Initial Learning Rate. Default: 0.001.
learningRate = 0.001
#Optimizer to use. 0 for classic SGD, 1 for Adam, 2 for RmsProp. Default: 2
sgd0orAdam1orRms2 = 2
#Type of momentum to use. 0 for standard momentum, 1 for Nesterov. Default: 1
classicMom0OrNesterov1 = 1
#Momentum Value to use. Default: 0.6
momentumValue = 0.6
#Non-Normalized (0) or Normalized momentum (1). Bear in mind that Normalized mom may result in smaller gradients and might need relatively higher Learning Rate. Default: 1
momNonNorm0orNormalized1 = 1
#Parameters for RmsProp. Default: rho=0.9, e=10**(-4) (1e-6 blew up the gradients. Haven't tried 1e-5 yet).
rhoRms = 0.9
epsilonRms = 10**(-4)

