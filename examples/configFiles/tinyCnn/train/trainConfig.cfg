# -*- coding: utf-8 -*-
#  Default values are set internally, if the corresponding parameter is not found in the configuration file.

#  [Optional but highly suggested] The name will be used for saving the models,logs and results.
#  Default: "trainSession"
sessionName = "trainSessionTiny"

#  [Required] The main folder that the output will be placed.
folderForOutput = "../../../output/"

#  [Optional] Path to a saved model, to load parameters from at beginning of the session. If one is also specified from command line, the latter will be used.
#cnnModelFilePath = "../../../output/models/placeholder"

#  [Optional] Log performance metrics for Tensorboard at end of subepochs. {True or False}
tensorboard_log = True


#  =======================Training=====================================

#  +++++++++++Input+++++++++++

#  [Required] A list that should contain as many entries as the channels of the input image (eg multi-modal MRI). The entries should be paths to files.
#             Those files should be listing the paths to the corresponding channels for each training-case. (see example files).
channelsTraining = ["./trainChannels_flair.cfg", "./trainChannels_t1c.cfg"]

#  [Required] The path to a file which should list paths to the Ground Truth labels of each training case.
gtLabelsTraining = "./trainGtLabels.cfg"

#  +++++++++++Sampling+++++++++++

#  [Optional] The path to a file, which should list paths to the Region-Of-Interest masks for each training case.
#  If ROI masks are provided, the training samples will be extracted only within it. Otherwise from whole volume.
roiMasksTraining = "./trainRoiMasks.cfg"

#  [Optional] Type-of-Sampling to use for training.
#  [Possible Values] 0 = Foreground / Background, 1 = Uniform, 2 = Whole Image (Not impl yet), 3 = Separately-Per-Class (Default).
typeOfSamplingForTraining = 0

#  +++++++++++Training Cycle (see documentation)+++++++++++

#  [Optionals but highly suggested as they are model dependent.]
#  How many epochs to train for. Default: 35
numberOfEpochs = 2
#  How many subepochs comprise an epoch. Every subepoch I get Accuracy reported. Default: 20
numberOfSubepochs = 2
#  Every subepoch, load the images from that many cases and extract new training samples. Default: 50
numOfCasesLoadedPerSubepoch = 50
#  Every subepoch, extract in total this many segments and load them on the GPU. Memory Limitated. Default: 1000
#  Note: This number in combination with the batchsize define the number of optimization steps per subepoch (=NumOfSegmentsOnGpu / BatchSize).
numberTrainingSegmentsLoadedOnGpuPerSubep = 1000

#  [Required] Batch size for training.
batchsize_train = 10

#  +++++++++++Learning Rate Schedule+++++++++++

#  [Optional] The type of schedule to use for Learning Rate annealing.
#  Schedule types:   'stable' : stable LR.      'predef' : lowering at predefined epochs.
#                    'poly' : lr=lr_base * (1-iter/max_iter) ^ 0.9 (from PSPNet)        'auto' : Lower LR when validation accuracy plateaus. Requires validation-on-samples enabled.
#  Note: LR schedule is important. We suggest running stable, observing when training error plateaus, and defined your "predefined schedule.
#        Otherwise, use poly with long-enough number of epoch.
#  Default: 'poly'
typeOfLearningRateSchedule = 'poly'

#  +++++++++++Data Augmentation+++++++++++++++

# [Optional] Augmentation applied on image-level. Comment it out or set to None for no augmentation. (Default: None)
# Currently supported types: 'affine' deformations by rotation and scaling (Slows down training).
# Parameters:
# Affine: 'prob': Chance [0.-1.] to augment an image (suggested: 0.5, default 0.0).
#         'max_rot_xyz': Max degrees rotation per axis. 'max_scaling': Max scaling [0.-1.].
#         'interp_order_imgs': Interpolation order for images (0, 1 or 2), higher is better but slower (suggested: 1 or 2).
augm_img_prms_tr = {'affine': { 'prob': 0.7, 'max_rot_xyz': (45., 45., 45.), 'max_scaling': 0.1, 'interp_order_imgs': 1 } }

# [Optional] Augmentation applied on segment-level. Comment it out or set to None for no augmentation. (Default: None)
# hist_dist: Shift and scale the intensity histogram. I' = (I + shift) * scale
#            Shift and scale values are sampled from Gaussians N(mu,std).
#            Set 'shift': None and/or 'scale': None to disable them.
# reflect:   Augment by flipping samples. Specify probabilities to flip X,Y,Z axis. Set None for disabling.
# rotate90:  Augment by rotating samples on xy,yz,xz planes by 0,90,180,270 degrees. (suggested: image-level 'affine' seems better but slower)
#            Give probabilities of flipping a plane by 0,90,180,270 degrees. Sum is internally normalised to 1.
#            NOTE: Size of segment must be isotropic otherwise error will be raised.
augm_sample_prms_tr = { 'hist_dist': {'shift': {'mu': 0., 'std': 0.05}, 'scale': {'mu': 1., 'std': 0.01} },
                        'reflect':   (0.5, 0., 0.),
                        'rotate90':  {'xy': {'0': 0.8, '90': 0.1, '180': 0., '270': 0.1},
                                      'yz': {'0': 0., '90': 0., '180': 0., '270': 0.},
                                      'xz': {'0': 0., '90': 0., '180': 0., '270': 0.} } }

