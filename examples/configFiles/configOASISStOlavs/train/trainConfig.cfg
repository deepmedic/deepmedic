#Default values are set internally, if the corresponding parameter is not found in the configuration file.

#[Optional but highly suggested] The name will be used for saving the models,logs and results.
#Default: "trainSession"
sessionName = "DeepMedicOASISStOlavsTrain"

#[Required] The main folder that the output will be placed.
folderForOutput = "../../../DeepMedicOASISStOlavs/"

#[Optional] The path to the saved CNN-model to use for training. Optional in the case the the model is specified from command line with the -model option. In this case, this entry file of the config file will be disregarded, and the one from the command line will be used.
cnnModelFilePath = "../../../output/models/placeholder"


#=======================Training=====================================

#+++++++++++Input+++++++++++

#[Required] A list that should contain as many entries as the channels of the input image (eg multi-modal MRI). The entries should be paths to files. Those files should be listing the paths to the corresponding channels for each training-case. (see example files).
channelsTraining = ["./trainChannels_t1c.cfg"]

#[Required] The path to a file which should list paths to the Ground Truth labels of each training case.
gtLabelsTraining = "./trainGtLabels.cfg"

#+++++++++++Sampling+++++++++++

#[Optional] The path to a file, which should list paths to the Region-Of-Interest masks for each training case.
#If ROI masks are provided, under default-sampling settings, the training samples will be extracted only within it. Otherwise from whole volume.
#This mask is also used for calculating mu and std intensities for intensity-augmentation, if performed.
#roiMasksTraining = "./trainRoiMasks.cfg"

#+++++++++++Advanced Sampling+++++++++++
#Note: Given variables in this "Advanced Sampling" section are disregarded if default settings are used, unless one sets: useDefaultTrainingSamplingFromGtAndRoi = False.

#[Optional] True in order to use default sampling for training. In this case, foreground samples are extracted from within the GT mask.
#Background samples are then extracted from the ROI (or full volume), excluding the GT. By default, equal number of samples are extracted from foreground and background.
#Note: Advanced options are disabled if default settings are used.
#Default: True
useDefaultTrainingSamplingFromGtAndRoi = True

#[Optional] Type-of-Sampling to use for training. 
#[Possible Values] 0 = Foreground / Background, 1 = Uniform, 2 = Full Image , 3 = Separately-Per-Class.
#Note: In case of (2) Full Image, ensure you provide segmentsDimTrain in modelConfig.cfg at least as big as image dimensions (+CNN's receptive field if padding is used).
#Default: 0
typeOfSamplingForTraining = 0

#[Optional] List the proportion (0.0 to 1.0) of samples to extract from each category of samples.
#Note: Depending on the Type-of-Sampling chosen, list must be of the form:
#	>> Fore/Background: [proportion-of-FOREground-samples, proportion-of-BACKground-samples], eg [0.3, 0.7]. IMPORTANT: FOREground first, background second!
#	>> Uniform or Full-Image: Not Applicable and disregarded if given.
#	>> Separate sampling of each class: [proportion-of-class-0(background), ..., proportion-of-class-N]
#Note: Values will be internally normalized (to add up to 1.0).
#Default: Foreground/Background or Separately-Each-Class : equal number of segments extracted for each of the categories. Uniform or Full-Image: N/A
proportionOfSamplesToExtractPerCategoryTraining = [0.5, 0.5]

#[Optional] This variable allows providing weighted-maps to indicate where to extract more segments for each category of samples. Higher weight means more samples from that area.
#The value provided should be a List with paths to files. As many files as the categories of samples for the chosen Sampling-Type.
#Similarly to the files listing the Ground Truth, Channels, etc per subject, these files should list the paths to the weight-maps of each subject for the corresponding category.
#Note: Number of files required: Fore/Backgr:2, Uniform:1, Full-Image:N/A, Separate each class:NumOfOutputClasses (Incl Backgr).
#IMPORTANT: Sequence of weight-maps is important!
#>> If Fore/Background type of sampling, provide for the FOREground first!
#>> If Separately sampling each class, provide weightmap-files in the same sequence as the class-labels in your Ground Truth! Eg background-0 first, class-1 second, etc.
#Default : If this variable is not provided, samples are extracted based on the Ground-Truth labels and the ROI. 
#weightedMapsForSamplingEachCategoryTrain = ["./weightMapsForeground.cfg", "./weightMapsBackground.cfg"]


#+++++++++++Training Cycle (see documentation)+++++++++++

#[Optionals but highly suggested as they are model dependent.]
#How many epochs to train for. Default: 35
numberOfEpochs = 35
#How many subepochs comprise an epoch. Every subepoch I get Accuracy reported. Default: 20
numberOfSubepochs = 20
#Every subepoch, load the images from that many cases and extract new training samples. Default: 50
numOfCasesLoadedPerSubepoch = 50
#Every subepoch, extract in total this many segments and load them on the GPU. Memory Limitated. Default: 1000
#Note: This number in combination with the batchSizeTraining, define the number of optimization steps per subepoch (=NumOfSegmentsOnGpu / BatchSize).
numberTrainingSegmentsLoadedOnGpuPerSubep = 1000

#+++++++++++Learning Rate Schedule+++++++++++

#[Optional] The type of schedule to use for Learning Rate annealing.
#0=Stable Decrease. 1=Auto (Lower LR when validation accuracy plateaus. Requires validation-on-samples). 2=Lower at predefined epochs. 3=Exponentially decrease LR, linearly increase Mom.
#Note: Training Schedule is very important. We suggest running stable and observing training error, then lower LR when it plateaus. Otherwise, use exponential but make sure to train for enough epochs.
stable0orAuto1orPredefined2orExponential3LrSchedule = 2

#[For Stable + Auto + Predefined] By how much to divide LR when lowering. Default: 2
whenDecreasingDivideLrBy = 2.0

#[For Stable + Auto] How many epochs to wait before decreasing again. Set Zero to never lower LR. Default: 3
#numEpochsToWaitBeforeLoweringLr = 3
#[For Auto] If validation accuracy increases more than this much, reset the waiting counter. Default: 0.0005
#minIncreaseInValidationAccuracyThatResetsWaiting = 0.0005

#[Required for Predefined] At which epochs to lower LR.
predefinedSchedule = [12, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46]

#[Required for Exponential] [First epoch to start lowering from, value for LR to reach at last epoch, value for Mom to reach at last epoch]
exponentialSchedForLrAndMom = [12, 1.0/(2**(7)), 0.9]

#+++++++++++Data Augmentation+++++++++++

#[Optional] Specify whether to reflect the images by 50% probability in respect to the X/Y/Z axis. Default: [False, False, False]
reflectImagesPerAxis = [True,False,False]

#[Optional] Augmentation by changing the mean and std of training samples. Default: False
performIntAugm = False
#I' = (I + shift) * multi
#[Optionals] We sample the "shift" and "multi" variable for each sample from a Gaussian distribution. Specify the mu and std.
#Defaults : [0, 0.1] and [1.,0.]
sampleIntAugmShiftWithMuAndStd = [0, 0.1]
sampleIntAugmMultiWithMuAndStd = [1., 0.0]

#+++++++++++Optimization+++++++++++
#[Optionals]
#Initial Learning Rate. Default: 0.001.
learningRate = 0.001
#Optimizer to use. 0 for classic SGD, 1 for Adam, 2 for RmsProp. Default: 2
sgd0orAdam1orRms2 = 2
#Type of momentum to use. 0 for standard momentum, 1 for Nesterov. Default: 1
classicMom0OrNesterov1 = 1
#Momentum Value to use. Default: 0.6
momentumValue = 0.6
#Non-Normalized (0) or Normalized momentum (1). Bear in mind that Normalized mom may result in smaller gradients and might need relatively higher Learning Rate. Default: 1
momNonNorm0orNormalized1 = 1
#Parameters for RmsProp. Default: rho=0.9, e=10**(-4) (1e-6 blew up the gradients. Haven't tried 1e-5 yet).
rhoRms = 0.9
epsilonRms = 10**(-4)

#[Optionals] Regularization L1 and L2.
#Defaults: L1_reg = 0.000001, L2_reg = 0.0001
L1_reg = 0.000001
L2_reg = 0.0001

#+++++++Freeze Layers++++++
#[Optional] Specify layers the weights of which you wish to be kept fixed during training (eg to use weights from pre-training). First layer is 1.
# One list for each of the normal, subsampled, and fully-connected (as 1x1 convs) pathways. For instance, provide [1,2,3] to keep first 3 layers fixed. [] or comment entry out to train all layers.
# Defaults: [] for the Normal and FC pathway. For the Subsampled pathway, if entry is not specified, we mirror the option used for the Normal pathway. 
layersToFreezeNormal = []
layersToFreezeSubsampled = []
layersToFreezeFC = []

#==================Validation=====================

#[Optionals] Specify whether to perform validation on samples and full-inference every few epochs. Default: False for both.
performValidationOnSamplesThroughoutTraining = True
performFullInferenceOnValidationImagesEveryFewEpochs = True

#[Required] Similar to corresponding parameter for training, but points to cases for validation.
channelsValidation = ["./validation/validationChannels_t1c.cfg"]

#[Required for validation on samples, optional for full-inference] Similar to corresponding parameter for training, but points to cases for validation.
gtLabelsValidation = "./validation/validationGtLabels.cfg"

#[Required] Similar to corresponding parameter for training. Only influences how accurately the validation samples will represent whole data. Memory bounded.
#Default: 3000
numberValidationSegmentsLoadedOnGpuPerSubep = 5000

#[Optional] Similar to corresponding parameter for training
#roiMasksValidation = "./validation/validationRoiMasks.cfg"

#+++++Advanced Validation Sampling+++++:
#Note: Given variables in this "Advanced Validation Sampling" section are disregarded if default settings are used, unless one sets: useDefaultUniformValidationSampling = False.

#[Optional] True in order to use default sampling for validation. Default is uniform sampling within the ROI (or whole volume if not provided).
#Note: Advanced options are disabled if default settings are used.
#Default: True
useDefaultUniformValidationSampling = True

#[Optional] Type-of-Sampling to use for Validation. See description of corresponding variable for training.
#Default: 1 (uniform sampling)
typeOfSamplingForVal = 1

#[Optional] List the proportion (0.0 to 1.0) of samples to extract from each category of samples. See description of corresponding variable for training.
#Default: Foreground/Background or Separately-Each-Class : equal number of segments extracted for each of the categories. Uniform or Full-Image: N/A
#proportionOfSamplesToExtractPerCategoryVal = [0.3, 0.7]

#[Optional]
#The following variable allows providing weighted-maps that indicate where to acquire more samples for each category/class. See description of corresponding variable for training.
#Default : If this variable is not provided, samples are extracted based on the Ground-Truth labels and the ROI. 
#weightedMapsForSamplingEachCategoryVal = ["./validation/weightMapsForeground.cfg", "./validation/weightMapsBackground.cfg"]


#+++++Full-Inference on validation cases+++++
#[Optional] How often (epochs) to perform full inference. It is time consuming... Default: 1
numberOfEpochsBetweenFullInferenceOnValImages = 1

#[Optionals] Specify whether to save the segmentation and probability maps for each class. Default: True to all
saveSegmentationVal = True
saveProbMapsForEachClassVal = [True, True, True, True, True]

#[Required if requested to save results] The path to a file, which should list names for each validation case, to name the results after.
namesForPredictionsPerCaseVal = "./validation/validationNamesOfPredictions.cfg"

#--Feature Maps--
#Feature maps can also be saved, but section is omitted here. See testing configuration.

#==========Generic=============
#[Optional] Pad images to fully convolve. Default: True
padInputImagesBool = True